#!/usr/bin/env python3
"""
Smart pattern analysis: Extract descriptions from already processed jobs
Build filter algorithm to skip non-entity descriptions
"""

import os
import json
import re
from pathlib import Path
from collections import Counter


def find_processed_jobs():
    """Find all completed jobs with Excel data"""
    jobs_dir = Path(".cypherx/jobs")

    if not jobs_dir.exists():
        return []

    processed = []
    for job_dir in jobs_dir.iterdir():
        if not job_dir.is_dir():
            continue

        excel_file = job_dir / "statement.xlsx"
        if excel_file.exists():
            processed.append(job_dir)

    return processed


def extract_descriptions_from_excel(excel_path):
    """Extract all descriptions from Excel file"""
    import pandas as pd

    descriptions = []

    try:
        # Read Transactions sheet
        df = pd.read_excel(excel_path, sheet_name="Transactions")

        if "Description" in df.columns:
            descs = df["Description"].dropna().tolist()
            descriptions.extend([str(d).strip() for d in descs if str(d).strip()])

    except Exception as e:
        print(f"   Warning: {e}")

    return descriptions


def analyze_for_entity_patterns(descriptions):
    """
    Surgical pattern analysis to identify:
    1. Descriptions that NEVER have entities (skip these)
    2. Descriptions that MIGHT have entities (call API for these)
    """

    print("\n" + "="*70)
    print("üî¨ SURGICAL PATTERN ANALYSIS")
    print("="*70)

    # NEGATIVE PATTERNS - These NEVER have person/company names
    negative_keywords = [
        # ATM/Cash operations
        r'\bATM\s+(W(ITH)?D(RAWAL)?L?|WDL|CASH)\b',
        r'\bCASH\s+W(ITH)?D(RAWAL)?L?\b',
        r'\bCASH\s+DEPOSIT\b',

        # Interest/Charges
        r'\bINTEREST\s+(CREDIT(ED)?|PAID|EARNED)\b',
        r'\b(SERVICE|ANNUAL|PROCESSING|MAINTENANCE)\s+(CHARGE|FEE)S?\b',
        r'\bMIN(IMUM)?\s+BAL(ANCE)?\s+(CHARGE|FEE)\b',
        r'\bSMS\s+CHARGES?\b',
        r'\bATM\s+(CHARGE|FEE)S?\b',

        # Tax/Govt
        r'\bGST\b',
        r'\bTDS\s+(DEDUCTED|DEBIT)\b',
        r'\bTAX\b',

        # Technical/Administrative
        r'\bREVERSAL\b',
        r'\bREFUND\b',
        r'\bCHEQUE\s+(BOUNCE|RETURN|DISHONO(U)?R)\b',
        r'\b(OPENING|CLOSING)\s+BALANCE\b',
        r'^\s*BAL(ANCE)?\s*:',
        r'^\s*TOTAL\s*$',

        # Card charges
        r'\b(DEBIT|CREDIT)\s+CARD\s+(ANNUAL|JOINING|PROCESSING)\s+(CHARGE|FEE)\b',
    ]

    # Compile combined pattern
    negative_pattern = re.compile('|'.join(negative_keywords), re.IGNORECASE)

    # Categorize descriptions
    skip_descriptions = []
    keep_descriptions = []

    for desc in descriptions:
        if negative_pattern.search(desc):
            skip_descriptions.append(desc)
        else:
            keep_descriptions.append(desc)

    total = len(descriptions)
    skip_count = len(skip_descriptions)
    keep_count = len(keep_descriptions)

    print(f"\nüìä Analysis Results:")
    print(f"   ‚Ä¢ Total descriptions: {total}")
    print(f"   ‚Ä¢ Skip (no entities): {skip_count} ({skip_count/total*100:.1f}%)")
    print(f"   ‚Ä¢ Keep (might have entities): {keep_count} ({keep_count/total*100:.1f}%)")

    # Show examples
    print(f"\nüö´ SKIP Examples (no person/company names):")
    for desc in skip_descriptions[:15]:
        print(f"   ‚Ä¢ {desc}")

    print(f"\n‚úÖ KEEP Examples (call DeepSeek API):")
    for desc in keep_descriptions[:15]:
        print(f"   ‚Ä¢ {desc}")

    return skip_descriptions, keep_descriptions, negative_pattern


def calculate_savings(skip_count, keep_count):
    """Calculate cost savings from filtering"""

    total = skip_count + keep_count

    # DeepSeek cost (from our test)
    cost_per_page_inr = 0.0091  # For 10 transactions
    cost_per_transaction_inr = cost_per_page_inr / 10

    print("\n" + "="*70)
    print("üí∞ COST SAVINGS ANALYSIS")
    print("="*70)

    # Without filter
    cost_without_filter = total * cost_per_transaction_inr

    # With filter
    cost_with_filter = keep_count * cost_per_transaction_inr

    # Savings
    savings_amount = cost_without_filter - cost_with_filter
    savings_percent = (savings_amount / cost_without_filter * 100) if cost_without_filter > 0 else 0

    print(f"\nüìà Current Dataset ({total} transactions):")
    print(f"   ‚Ä¢ Without filter: ‚Çπ{cost_without_filter:.4f}")
    print(f"   ‚Ä¢ With filter: ‚Çπ{cost_with_filter:.4f}")
    print(f"   ‚Ä¢ Savings: ‚Çπ{savings_amount:.4f} ({savings_percent:.1f}%)")

    print(f"\nüöÄ Projected for 10,000 transactions:")
    factor = 10000 / total if total > 0 else 1
    print(f"   ‚Ä¢ Without filter: ‚Çπ{cost_without_filter * factor:.2f}")
    print(f"   ‚Ä¢ With filter: ‚Çπ{cost_with_filter * factor:.2f}")
    print(f"   ‚Ä¢ Savings: ‚Çπ{savings_amount * factor:.2f}")

    print(f"\n‚ö° Speed Improvement:")
    time_per_page = 38.87  # seconds from our test
    pages_saved = (skip_count / 10) if skip_count > 0 else 0
    time_saved = pages_saved * time_per_page
    print(f"   ‚Ä¢ Pages saved: {pages_saved:.0f}")
    print(f"   ‚Ä¢ Time saved: {time_saved:.0f}s ({time_saved/60:.1f} minutes)")


def generate_filter_function():
    """Generate the actual Python filter function to use in production"""

    code = '''
def should_extract_entities(description: str) -> bool:
    """
    Pre-filter to determine if a description might contain person/company entities.
    Returns True if we should call DeepSeek API, False if we can skip.

    This saves ~50-70% of API calls and costs!
    """

    # Patterns that NEVER have person/company names
    skip_patterns = [
        r'\\bATM\\s+(W(ITH)?D(RAWAL)?L?|WDL|CASH)\\b',
        r'\\bCASH\\s+W(ITH)?D(RAWAL)?L?\\b',
        r'\\bCASH\\s+DEPOSIT\\b',
        r'\\bINTEREST\\s+(CREDIT(ED)?|PAID|EARNED)\\b',
        r'\\b(SERVICE|ANNUAL|PROCESSING|MAINTENANCE)\\s+(CHARGE|FEE)S?\\b',
        r'\\bMIN(IMUM)?\\s+BAL(ANCE)?\\s+(CHARGE|FEE)\\b',
        r'\\bSMS\\s+CHARGES?\\b',
        r'\\bATM\\s+(CHARGE|FEE)S?\\b',
        r'\\bGST\\b',
        r'\\bTDS\\s+(DEDUCTED|DEBIT)\\b',
        r'\\bTAX\\b',
        r'\\bREVERSAL\\b',
        r'\\bREFUND\\b',
        r'\\bCHEQUE\\s+(BOUNCE|RETURN|DISHONO(U)?R)\\b',
        r'\\b(OPENING|CLOSING)\\s+BALANCE\\b',
        r'^\\s*BAL(ANCE)?\\s*:',
        r'^\\s*TOTAL\\s*$',
        r'\\b(DEBIT|CREDIT)\\s+CARD\\s+(ANNUAL|JOINING|PROCESSING)\\s+(CHARGE|FEE)\\b',
    ]

    import re
    skip_regex = re.compile('|'.join(skip_patterns), re.IGNORECASE)

    # If matches any skip pattern, return False (don't call API)
    if skip_regex.search(description):
        return False

    # Otherwise, return True (call API to extract entities)
    return True


# Example usage:
descriptions = [
    "ATM WDL CASH",                           # False - skip
    "INTEREST CREDITED",                      # False - skip
    "UPI-AMAZON PAY INDIA",                   # True - call API
    "NEFT-JOHN DOE-CONSULTANCY FEE",         # True - call API
]

for desc in descriptions:
    if should_extract_entities(desc):
        print(f"‚úÖ Call API: {desc}")
    else:
        print(f"üö´ Skip: {desc}")
'''

    return code


def main():
    print("="*70)
    print("üß† SMART PATTERN ANALYZER")
    print("="*70)

    # Option 1: Use already processed jobs
    print("\nüîç Looking for processed jobs...")
    job_dirs = find_processed_jobs()

    all_descriptions = []

    if job_dirs:
        print(f"‚úì Found {len(job_dirs)} processed jobs")

        for job_dir in job_dirs:
            excel_file = job_dir / "statement.xlsx"
            print(f"\nüìÑ Extracting from: {job_dir.name}")

            descs = extract_descriptions_from_excel(excel_file)
            all_descriptions.extend(descs)
            print(f"   ‚Ä¢ Extracted {len(descs)} descriptions")

    if not all_descriptions:
        print("\n‚ö†Ô∏è  No processed jobs found. Using sample descriptions...")
        # Fallback to sample descriptions
        all_descriptions = [
            "ATM WDL ICICI BANK",
            "CASH WITHDRAWAL",
            "INTEREST CREDITED",
            "SERVICE CHARGES",
            "GST",
            "TDS DEDUCTED",
            "REVERSAL",
            "OPENING BALANCE",
            "UPI-AMAZON PAY INDIA PRI-QPAYM",
            "NEFT-HDFC BANK LTD-SALARY CREDIT",
            "SWIGGY-BANGALORE-FOOD ORDER",
            "FLIPKART INTERNET PVT LTD",
            "NETFLIX.COM MONTHLY SUBSCRIPTION",
            "GOOGLE WORKSPACE PAYMENT",
            "Payment to John Smith for consultancy",
            "IMPS-ROBERT JOHN-PAYMENT",
        ]

    print(f"\n‚úì Total descriptions collected: {len(all_descriptions)}")

    # Analyze patterns
    skip_descs, keep_descs, filter_pattern = analyze_for_entity_patterns(all_descriptions)

    # Calculate savings
    calculate_savings(len(skip_descs), len(keep_descs))

    # Generate filter function
    print("\n" + "="*70)
    print("üìù GENERATED FILTER FUNCTION")
    print("="*70)
    print("\nCopy this function to your production code:")
    print(generate_filter_function())

    print("\n" + "="*70)
    print("‚úÖ ANALYSIS COMPLETE!")
    print("="*70)
    print("\nNext steps:")
    print("1. Integrate the filter function into your statement processing pipeline")
    print("2. Call DeepSeek API only for descriptions that pass the filter")
    print("3. Save money and time! üí∞‚ö°")


if __name__ == "__main__":
    main()